\thispagestyle{empty} 
\SpecialTitle{Abstract}
\noindent Most​‍​‌‍​‍‌​‍​‌‍​‍‌ of the time, the detection of misinformation on social media platforms is done by treating text and images as separate entities and sometimes by simply combining them through concatenation, which results in weak cross-modal alignment and limited understanding. The poor integration of the two modalities leads to a low level of interaction between the two which in turn results in less accurate predictions and a limited understanding of the predictions. If the text and image of a post are in contradiction, then systems tend to get confused, and they provide little or no explanation for their decisions. In response to these issues, recent progress in multimodal learning has been made which helps to better align and fuse text and images. Contrastive learning is a method that helps the model to understand that the related text-image pairs should be closer together, and unrelated ones should be farther apart. Cross-modal attention then helps the system to use the modality that is more relevant for each individual post.

In​‍​‌‍​‍‌​‍​‌‍​‍‌ order to clarify the process, the system uses explainability methods like Grad-CAM that visually show the parts of an image that had the most impact, and token-level SHAP that points out the words in the text that were the main contributors for the ​‍​‌‍​‍‌​‍​‌‍​‍‌decision.

This work aims at constructing a complete fake news detection system for Twitter posts, which integrates BERT for textual comprehension and ResNet50 for pictorial analysis. Both parts will be contrastively pre-trained with contrastive loss to merge their representations, and their outputs will be combined through cross-modal attention before classification. This technique is anticipated to produce accurate predictions and facilitate easy visual explanations of how each decision was arrived at. ​‍​‌‍​‍‌​‍​‌‍​‍‌

\vspace{5mm}
\noindent\textbf{\textit{Keywords}}:~\textit{Misinformation Detection};~\textit{Multimodal Learning};~\textit{Contrastive Learning};~\textit{Cross-Modal Fusion};~\textit{BERT};~\textit{ResNet50};~\textit{Deep Fake};~\textit{Explainability};~\textit{Grad-CAM++};~\textit{SHAP}.
